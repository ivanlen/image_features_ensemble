{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features and images ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook are going to ensemble features with images in a classification problem.\n",
    "The main idea is to show how to ensemble CNN with other arc\n",
    "\n",
    "\n",
    "The dataset loading code was taken from https://www.kaggle.com/abhmul/keras-convnet-lb-0-0052-w-visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/coding_projects/testing3/lib/python3.6/site-packages/keras_preprocessing/image.py:492: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n",
      "/home/ivan/coding_projects/testing3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1639: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data loaded!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# If you want to use Theano, all you need to change\n",
    "# is the dim ordering whenever you are dealing with\n",
    "# the image array. Instead of\n",
    "# (samples, rows, cols, channels) it should be\n",
    "# (samples, channels, rows, cols)\n",
    "\n",
    "# Keras stuff\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# A large amount of the data loading code is based on najeebkhan's kernel\n",
    "# Check it out at https://www.kaggle.com/najeebkhan/leaf-classification/neural-network-through-keras\n",
    "root = './all'\n",
    "np.random.seed(2016)\n",
    "split_random_state = 7\n",
    "split = .8\n",
    "image_max_size = 512\n",
    "\n",
    "\n",
    "def load_numeric_training(standardize=False):\n",
    "    \"\"\"\n",
    "    Loads the pre-extracted features for the training data\n",
    "    and returns a tuple of the image ids, the data, and the labels\n",
    "    \"\"\"\n",
    "    # Read data from the CSV file\n",
    "    data = pd.read_csv(os.path.join(root, 'train.csv'))\n",
    "    ID = data.pop('id')\n",
    "\n",
    "    # Since the labels are textual, so we encode them categorically\n",
    "    y = data.pop('species')\n",
    "    y = LabelEncoder().fit(y).transform(y)\n",
    "    # standardize the data by setting the mean to 0 and std to 1\n",
    "    X = StandardScaler().fit(data).transform(data) if standardize else data.values\n",
    "\n",
    "    return ID, X, y\n",
    "\n",
    "\n",
    "def load_numeric_test(scaler, standardize=False):\n",
    "    \"\"\"\n",
    "    Loads the pre-extracted features for the test data\n",
    "    and returns a tuple of the image ids, the data\n",
    "    \"\"\"\n",
    "    test = pd.read_csv(os.path.join(root, 'test.csv'))\n",
    "    ID = test.pop('id')\n",
    "    # standardize the data by setting the mean to 0 and std to 1\n",
    "    test = StandardScaler().fit(test).transform(test) if standardize else test.values\n",
    "    return ID, test\n",
    "\n",
    "\n",
    "def resize_img(img, max_dim=image_max_size):\n",
    "    \"\"\"\n",
    "    Resize the image to so the maximum side is of size max_dim\n",
    "    Returns a new image of the right size\n",
    "    \"\"\"\n",
    "    # Get the axis with the larger dimension\n",
    "    max_ax = max((0, 1), key=lambda i: img.size[i])\n",
    "    # Scale both axes so the image's largest dimension is max_dim\n",
    "    scale = max_dim / float(img.size[max_ax])\n",
    "    return img.resize((int(img.size[0] * scale), int(img.size[1] * scale)))\n",
    "\n",
    "\n",
    "def load_image_data(ids, max_dim=image_max_size, center=True):\n",
    "    \"\"\"\n",
    "    Takes as input an array of image ids and loads the images as numpy\n",
    "    arrays with the images resized so the longest side is max-dim length.\n",
    "    If center is True, then will place the image in the center of\n",
    "    the output array, otherwise it will be placed at the top-left corner.\n",
    "    \"\"\"\n",
    "    # Initialize the output array\n",
    "    # NOTE: Theano users comment line below and\n",
    "    X = np.empty((len(ids), max_dim, max_dim, 1))\n",
    "    # X = np.empty((len(ids), 1, max_dim, max_dim)) # uncomment this\n",
    "    for i, idee in enumerate(ids):\n",
    "        # Turn the image into an array\n",
    "        x = resize_img(load_img(os.path.join(root, 'images', str(idee) + '.jpg'), grayscale=True), max_dim=max_dim)\n",
    "        x = img_to_array(x)\n",
    "        # Get the corners of the bounding box for the image\n",
    "        # NOTE: Theano users comment the two lines below and\n",
    "        length = x.shape[0]\n",
    "        width = x.shape[1]\n",
    "        # length = x.shape[1] # uncomment this\n",
    "        # width = x.shape[2] # uncomment this\n",
    "        if center:\n",
    "            h1 = int((max_dim - length) / 2)\n",
    "            h2 = h1 + length\n",
    "            w1 = int((max_dim - width) / 2)\n",
    "            w2 = w1 + width\n",
    "        else:\n",
    "            h1, w1 = 0, 0\n",
    "            h2, w2 = (length, width)\n",
    "        # Insert into image matrix\n",
    "        # NOTE: Theano users comment line below and\n",
    "        X[i, h1:h2, w1:w2, 0:1] = x\n",
    "        # X[i, 0:1, h1:h2, w1:w2] = x  # uncomment this\n",
    "    # Scale the array values so they are between 0 and 1\n",
    "    return np.around(X / 255.0)\n",
    "\n",
    "\n",
    "def load_train_data(split=split, random_state=None):\n",
    "    \"\"\"\n",
    "    Loads the pre-extracted feature and image training data and\n",
    "    splits them into training and cross-validation.\n",
    "    Returns one tuple for the training data and one for the validation\n",
    "    data. Each tuple is in the order pre-extracted features, images,\n",
    "    and labels.\n",
    "    \"\"\"\n",
    "    # Load the pre-extracted features\n",
    "    ID, X_num_tr, y = load_numeric_training()\n",
    "    # Load the image data\n",
    "    X_img_tr = load_image_data(ID)\n",
    "    # Split them into validation and cross-validation\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, train_size=split, random_state=random_state)\n",
    "    train_ind, test_ind = next(sss.split(X_num_tr, y))\n",
    "    X_num_val, X_img_val, y_val = X_num_tr[test_ind], X_img_tr[test_ind], y[test_ind]\n",
    "    X_num_tr, X_img_tr, y_tr = X_num_tr[train_ind], X_img_tr[train_ind], y[train_ind]\n",
    "    return (X_num_tr, X_img_tr, y_tr), (X_num_val, X_img_val, y_val)\n",
    "\n",
    "\n",
    "def load_test_data():\n",
    "    \"\"\"\n",
    "    Loads the pre-extracted feature and image test data.\n",
    "    Returns a tuple in the order ids, pre-extracted features,\n",
    "    and images.\n",
    "    \"\"\"\n",
    "    # Load the pre-extracted features\n",
    "    ID, X_num_te = load_numeric_test()\n",
    "    # Load the image data\n",
    "    X_img_te = load_image_data(ID)\n",
    "    return ID, X_num_te, X_img_te\n",
    "\n",
    "print('Loading the training data...')\n",
    "(X_num_tr, X_img_tr, y_tr), (X_num_val, X_img_val, y_val) = load_train_data(random_state=split_random_state)\n",
    "y_tr_cat = to_categorical(y_tr)\n",
    "y_val_cat = to_categorical(y_val)\n",
    "print('Training data loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "n_cats = len(np.unique(y_tr))\n",
    "print(n_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(792, 192)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.011719, 0.011719, 0.019531, ..., 0.012695, 0.046875, 0.025391],\n",
       "       [0.009766, 0.011719, 0.033203, ..., 0.003906, 0.024414, 0.047852],\n",
       "       [0.025391, 0.017578, 0.023438, ..., 0.      , 0.008789, 0.004883],\n",
       "       ...,\n",
       "       [0.021484, 0.080078, 0.013672, ..., 0.052734, 0.004883, 0.012695],\n",
       "       [0.017578, 0.029297, 0.048828, ..., 0.005859, 0.      , 0.015625],\n",
       "       [0.070312, 0.12305 , 0.011719, ..., 0.      , 0.      , 0.005859]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using only features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential\n",
    "from keras import Model\n",
    "from keras.layers import ReLU, Dense, Conv2D, Softmax, Conv1D, Flatten, Dropout, Input,GlobalMaxPooling2D,MaxPooling2D, Convolution2D, Concatenate, merge\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 150)               28950     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 120)               18120     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 110)               13310     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 105)               11655     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 100)               10600     \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 99)                9999      \n",
      "=================================================================\n",
      "Total params: 92,634\n",
      "Trainable params: 92,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model \n",
    "model = Sequential()\n",
    "model.add(Dense(150, input_shape = (192,), activation = 'relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(120, activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(110, activation = 'relu'))\n",
    "model.add(Dense(105, activation = 'relu'))\n",
    "model.add(Dense(100, activation = 'relu'))\n",
    "model.add(Dense(n_cats,activation = 'softmax', name = 'out_layer'))\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, \n",
    "                        patience=5, verbose=1, mode='auto', \n",
    "                        min_delta=0.01,  min_lr=0)\n",
    "erl = EarlyStopping(monitor='val_loss',\n",
    "                        patience=10, verbose=1, mode='auto', \n",
    "                        min_delta=0.01)\n",
    "\n",
    "callbacks = [rlr,erl]\n",
    "\n",
    "model.compile(optimizer='adam', loss= 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 792 samples, validate on 99 samples\n",
      "Epoch 1/100\n",
      "792/792 [==============================] - 1s 2ms/step - loss: 4.5970 - acc: 0.0114 - val_loss: 4.5822 - val_acc: 0.0404\n",
      "Epoch 2/100\n",
      "792/792 [==============================] - 0s 423us/step - loss: 4.4633 - acc: 0.0189 - val_loss: 4.0160 - val_acc: 0.0404\n",
      "Epoch 3/100\n",
      "792/792 [==============================] - 0s 432us/step - loss: 3.6154 - acc: 0.0732 - val_loss: 2.9488 - val_acc: 0.2020\n",
      "Epoch 4/100\n",
      "792/792 [==============================] - 0s 424us/step - loss: 2.7724 - acc: 0.1667 - val_loss: 2.3473 - val_acc: 0.3636\n",
      "Epoch 5/100\n",
      "792/792 [==============================] - 0s 420us/step - loss: 2.3715 - acc: 0.2727 - val_loss: 2.1617 - val_acc: 0.2626\n",
      "Epoch 6/100\n",
      "792/792 [==============================] - 0s 425us/step - loss: 2.0487 - acc: 0.3561 - val_loss: 1.9131 - val_acc: 0.4545\n",
      "Epoch 7/100\n",
      "792/792 [==============================] - 0s 424us/step - loss: 1.9199 - acc: 0.3674 - val_loss: 1.7410 - val_acc: 0.4949\n",
      "Epoch 8/100\n",
      "792/792 [==============================] - 0s 425us/step - loss: 1.7131 - acc: 0.4369 - val_loss: 1.6308 - val_acc: 0.4848\n",
      "Epoch 9/100\n",
      "792/792 [==============================] - 0s 426us/step - loss: 1.5728 - acc: 0.4583 - val_loss: 1.5477 - val_acc: 0.5657\n",
      "Epoch 10/100\n",
      "792/792 [==============================] - 0s 424us/step - loss: 1.4934 - acc: 0.4886 - val_loss: 1.3928 - val_acc: 0.6162\n",
      "Epoch 11/100\n",
      "792/792 [==============================] - 0s 421us/step - loss: 1.3702 - acc: 0.5177 - val_loss: 1.4883 - val_acc: 0.5556\n",
      "Epoch 12/100\n",
      "792/792 [==============================] - 0s 428us/step - loss: 1.2546 - acc: 0.5593 - val_loss: 1.3474 - val_acc: 0.6667\n",
      "Epoch 13/100\n",
      "792/792 [==============================] - 0s 426us/step - loss: 1.2529 - acc: 0.5821 - val_loss: 1.1745 - val_acc: 0.6465\n",
      "Epoch 14/100\n",
      "792/792 [==============================] - 0s 418us/step - loss: 1.0856 - acc: 0.6136 - val_loss: 1.1796 - val_acc: 0.6263\n",
      "Epoch 15/100\n",
      "792/792 [==============================] - 0s 422us/step - loss: 1.0116 - acc: 0.6439 - val_loss: 1.0995 - val_acc: 0.7273\n",
      "Epoch 16/100\n",
      "792/792 [==============================] - 0s 424us/step - loss: 1.0260 - acc: 0.6225 - val_loss: 1.1092 - val_acc: 0.6162\n",
      "Epoch 17/100\n",
      "792/792 [==============================] - 0s 434us/step - loss: 0.9510 - acc: 0.6616 - val_loss: 1.1333 - val_acc: 0.5960\n",
      "Epoch 18/100\n",
      "792/792 [==============================] - 0s 424us/step - loss: 0.9168 - acc: 0.6894 - val_loss: 1.0031 - val_acc: 0.7071\n",
      "Epoch 19/100\n",
      "792/792 [==============================] - 0s 432us/step - loss: 0.8223 - acc: 0.7121 - val_loss: 0.9765 - val_acc: 0.7273\n",
      "Epoch 20/100\n",
      "792/792 [==============================] - 0s 426us/step - loss: 0.7420 - acc: 0.7399 - val_loss: 1.1254 - val_acc: 0.7071\n",
      "Epoch 21/100\n",
      "792/792 [==============================] - 0s 427us/step - loss: 0.8255 - acc: 0.7210 - val_loss: 0.9296 - val_acc: 0.7475\n",
      "Epoch 22/100\n",
      "792/792 [==============================] - 0s 423us/step - loss: 0.7265 - acc: 0.7513 - val_loss: 0.9392 - val_acc: 0.7273\n",
      "Epoch 23/100\n",
      "792/792 [==============================] - 0s 421us/step - loss: 0.7225 - acc: 0.7361 - val_loss: 0.8980 - val_acc: 0.7172\n",
      "Epoch 24/100\n",
      "792/792 [==============================] - 0s 425us/step - loss: 0.7051 - acc: 0.7487 - val_loss: 0.8743 - val_acc: 0.7576\n",
      "Epoch 25/100\n",
      "792/792 [==============================] - 0s 427us/step - loss: 0.5997 - acc: 0.7866 - val_loss: 0.8996 - val_acc: 0.7475\n",
      "Epoch 26/100\n",
      "792/792 [==============================] - 0s 423us/step - loss: 0.6354 - acc: 0.7740 - val_loss: 0.9763 - val_acc: 0.7172\n",
      "Epoch 27/100\n",
      "792/792 [==============================] - 0s 425us/step - loss: 0.5753 - acc: 0.8106 - val_loss: 0.9575 - val_acc: 0.7273\n",
      "Epoch 28/100\n",
      "792/792 [==============================] - 0s 426us/step - loss: 0.5521 - acc: 0.8056 - val_loss: 0.8436 - val_acc: 0.7576\n",
      "Epoch 29/100\n",
      "792/792 [==============================] - 0s 421us/step - loss: 0.5658 - acc: 0.8169 - val_loss: 0.8886 - val_acc: 0.7778\n",
      "Epoch 30/100\n",
      "792/792 [==============================] - 0s 425us/step - loss: 0.4934 - acc: 0.8346 - val_loss: 0.9387 - val_acc: 0.7677\n",
      "Epoch 31/100\n",
      "792/792 [==============================] - 0s 427us/step - loss: 0.5507 - acc: 0.8308 - val_loss: 0.7948 - val_acc: 0.7980\n",
      "Epoch 32/100\n",
      "792/792 [==============================] - 0s 428us/step - loss: 0.4862 - acc: 0.8333 - val_loss: 0.8724 - val_acc: 0.8081\n",
      "Epoch 33/100\n",
      "792/792 [==============================] - 0s 424us/step - loss: 0.4502 - acc: 0.8460 - val_loss: 0.8398 - val_acc: 0.7576\n",
      "Epoch 34/100\n",
      "792/792 [==============================] - 0s 422us/step - loss: 0.5007 - acc: 0.8232 - val_loss: 0.8371 - val_acc: 0.8081\n",
      "Epoch 35/100\n",
      "792/792 [==============================] - 0s 428us/step - loss: 0.5192 - acc: 0.8270 - val_loss: 0.7372 - val_acc: 0.8384\n",
      "Epoch 36/100\n",
      "792/792 [==============================] - 0s 422us/step - loss: 0.4465 - acc: 0.8472 - val_loss: 0.8806 - val_acc: 0.7980\n",
      "Epoch 37/100\n",
      "792/792 [==============================] - 0s 424us/step - loss: 0.3702 - acc: 0.8699 - val_loss: 0.8374 - val_acc: 0.7980\n",
      "Epoch 38/100\n",
      "792/792 [==============================] - 0s 422us/step - loss: 0.3776 - acc: 0.8649 - val_loss: 0.8746 - val_acc: 0.7778\n",
      "Epoch 39/100\n",
      "792/792 [==============================] - 0s 432us/step - loss: 0.3904 - acc: 0.8674 - val_loss: 0.7740 - val_acc: 0.8182\n",
      "Epoch 40/100\n",
      "792/792 [==============================] - 0s 419us/step - loss: 0.4101 - acc: 0.8485 - val_loss: 0.7501 - val_acc: 0.8182\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 41/100\n",
      "792/792 [==============================] - 0s 427us/step - loss: 0.2897 - acc: 0.9028 - val_loss: 0.6843 - val_acc: 0.8485\n",
      "Epoch 42/100\n",
      "792/792 [==============================] - 0s 425us/step - loss: 0.2872 - acc: 0.9015 - val_loss: 0.6111 - val_acc: 0.8485\n",
      "Epoch 43/100\n",
      "792/792 [==============================] - 0s 423us/step - loss: 0.2348 - acc: 0.9255 - val_loss: 0.6178 - val_acc: 0.8485\n",
      "Epoch 44/100\n",
      "792/792 [==============================] - 0s 426us/step - loss: 0.2404 - acc: 0.9205 - val_loss: 0.7224 - val_acc: 0.8384\n",
      "Epoch 45/100\n",
      "792/792 [==============================] - 0s 420us/step - loss: 0.2193 - acc: 0.9318 - val_loss: 0.6833 - val_acc: 0.8889\n",
      "Epoch 46/100\n",
      "792/792 [==============================] - 0s 420us/step - loss: 0.2490 - acc: 0.9154 - val_loss: 0.7175 - val_acc: 0.8485\n",
      "Epoch 47/100\n",
      "792/792 [==============================] - 0s 428us/step - loss: 0.2244 - acc: 0.9268 - val_loss: 0.6669 - val_acc: 0.8384\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 48/100\n",
      "792/792 [==============================] - 0s 418us/step - loss: 0.1888 - acc: 0.9432 - val_loss: 0.6520 - val_acc: 0.8687\n",
      "Epoch 49/100\n",
      "792/792 [==============================] - 0s 424us/step - loss: 0.1686 - acc: 0.9432 - val_loss: 0.7030 - val_acc: 0.8485\n",
      "Epoch 50/100\n",
      "792/792 [==============================] - 0s 424us/step - loss: 0.1804 - acc: 0.9407 - val_loss: 0.7518 - val_acc: 0.8485\n",
      "Epoch 51/100\n",
      "792/792 [==============================] - 0s 424us/step - loss: 0.1824 - acc: 0.9419 - val_loss: 0.6951 - val_acc: 0.8485\n",
      "Epoch 52/100\n",
      "792/792 [==============================] - 0s 426us/step - loss: 0.1896 - acc: 0.9306 - val_loss: 0.7161 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 00052: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f253d06c7f0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_num_tr, y_tr_cat, batch_size = 10, epochs = 100, validation_data=(X_num_val, y_val_cat), callbacks=[rlr, erl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, features, targets, \n",
    "                 n_classes =99, batch_size=32,  shuffle=True):\n",
    "        'Initialization'\n",
    "        self.n_classes = n_classes\n",
    "        self.n_vals = len(targets)\n",
    "        self.list_IDs = np.arange(self.n_vals)\n",
    "        self.batch_size = batch_size\n",
    "        self.features = features\n",
    "        self.shuffle = shuffle\n",
    "        self.targets = targets\n",
    "        self.targets_mc = keras.utils.to_categorical(targets, num_classes=self.n_classes)\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = self.features[list_IDs_temp]\n",
    "        y = self.targets_mc[list_IDs_temp]\n",
    "\n",
    "#        # Generate data\n",
    "#        for i, ID in enumerate(list_IDs_temp):\n",
    "#            # Store sample\n",
    "#            X[i,] = np.load('data/' + ID + '.npy')\n",
    "#\n",
    "#            # Store class\n",
    "#            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 64)                12352     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 99)                12771     \n",
      "=================================================================\n",
      "Total params: 33,443\n",
      "Trainable params: 33,443\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "params = {'batch_size': 10,\n",
    "          'n_classes': 99,\n",
    "          'shuffle': True}\n",
    "\n",
    "training_generator = DataGenerator(X_num_tr,y_tr, **params)\n",
    "validation_generator = DataGenerator(X_num_val,y_val, **params)\n",
    "\n",
    "\n",
    "# model \n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape = (192,), activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "model.add(Dense(n_cats,activation = 'softmax', name = 'out_layer'))\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, \n",
    "                        patience=5, verbose=1, mode='auto', \n",
    "                        min_delta=0.01,  min_lr=0)\n",
    "erl = EarlyStopping(monitor='val_loss',\n",
    "                        patience=10, verbose=1, mode='auto', \n",
    "                        min_delta=0.01)\n",
    "\n",
    "model.compile(optimizer='adam', loss= 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 4.5885 - acc: 0.0291 - val_loss: 4.5564 - val_acc: 0.1111\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 4.4960 - acc: 0.0772 - val_loss: 4.3507 - val_acc: 0.1000\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 4.1173 - acc: 0.0709 - val_loss: 3.7371 - val_acc: 0.1889\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 3.4915 - acc: 0.1696 - val_loss: 3.0584 - val_acc: 0.3667\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 2.9463 - acc: 0.2532 - val_loss: 2.6376 - val_acc: 0.4222\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 2.5772 - acc: 0.3177 - val_loss: 2.3182 - val_acc: 0.4889\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 2.3038 - acc: 0.3949 - val_loss: 2.0934 - val_acc: 0.5222\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 2.1008 - acc: 0.4291 - val_loss: 1.9029 - val_acc: 0.6556\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.9004 - acc: 0.4759 - val_loss: 1.7549 - val_acc: 0.5889\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.7908 - acc: 0.4924 - val_loss: 1.6356 - val_acc: 0.6667\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.6255 - acc: 0.5203 - val_loss: 1.5318 - val_acc: 0.6556\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.5497 - acc: 0.5354 - val_loss: 1.3262 - val_acc: 0.7000\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.4383 - acc: 0.5861 - val_loss: 1.3089 - val_acc: 0.7556\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.3613 - acc: 0.5962 - val_loss: 1.2058 - val_acc: 0.7333\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.2717 - acc: 0.6354 - val_loss: 1.1517 - val_acc: 0.7667\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.1857 - acc: 0.6608 - val_loss: 1.1395 - val_acc: 0.7556\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.1538 - acc: 0.6671 - val_loss: 1.0579 - val_acc: 0.7556\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.0742 - acc: 0.6785 - val_loss: 1.0389 - val_acc: 0.7778\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.0486 - acc: 0.6886 - val_loss: 0.9686 - val_acc: 0.7667\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.9781 - acc: 0.6873 - val_loss: 0.9903 - val_acc: 0.7556\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.9192 - acc: 0.7494 - val_loss: 0.8897 - val_acc: 0.8333\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.9141 - acc: 0.7342 - val_loss: 0.8319 - val_acc: 0.8111\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.8426 - acc: 0.7468 - val_loss: 0.7940 - val_acc: 0.8333\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.8098 - acc: 0.7595 - val_loss: 0.8303 - val_acc: 0.8000\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.8024 - acc: 0.7519 - val_loss: 0.7743 - val_acc: 0.8667\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.7296 - acc: 0.7772 - val_loss: 0.7653 - val_acc: 0.8111\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.7311 - acc: 0.7810 - val_loss: 0.7743 - val_acc: 0.8333\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.7102 - acc: 0.7759 - val_loss: 0.6846 - val_acc: 0.8556\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6710 - acc: 0.7962 - val_loss: 0.7021 - val_acc: 0.8556\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.6860 - acc: 0.7772 - val_loss: 0.6988 - val_acc: 0.8444\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5946 - acc: 0.8367 - val_loss: 0.5941 - val_acc: 0.8778\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.6315 - acc: 0.8013 - val_loss: 0.6627 - val_acc: 0.8778\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5843 - acc: 0.8177 - val_loss: 0.6661 - val_acc: 0.8444\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.5821 - acc: 0.8152 - val_loss: 0.6632 - val_acc: 0.8333\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5873 - acc: 0.8177 - val_loss: 0.6205 - val_acc: 0.8556\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.5298 - acc: 0.8443 - val_loss: 0.6387 - val_acc: 0.8444\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4927 - acc: 0.8709 - val_loss: 0.5593 - val_acc: 0.9000\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4774 - acc: 0.8734 - val_loss: 0.5547 - val_acc: 0.8556\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4709 - acc: 0.8608 - val_loss: 0.5885 - val_acc: 0.8667\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4745 - acc: 0.8532 - val_loss: 0.5279 - val_acc: 0.9111\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4504 - acc: 0.8684 - val_loss: 0.5926 - val_acc: 0.8556\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4167 - acc: 0.8823 - val_loss: 0.5436 - val_acc: 0.8556\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4377 - acc: 0.8684 - val_loss: 0.4344 - val_acc: 0.9000\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4158 - acc: 0.8911 - val_loss: 0.5476 - val_acc: 0.9000\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4301 - acc: 0.8747 - val_loss: 0.5807 - val_acc: 0.8667\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.3939 - acc: 0.8899 - val_loss: 0.5569 - val_acc: 0.8556\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4116 - acc: 0.8684 - val_loss: 0.5835 - val_acc: 0.8778\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.3946 - acc: 0.8848 - val_loss: 0.5521 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4082 - acc: 0.8709 - val_loss: 0.5548 - val_acc: 0.8778\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.3920 - acc: 0.8911 - val_loss: 0.5608 - val_acc: 0.8889\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.3913 - acc: 0.8937 - val_loss: 0.5317 - val_acc: 0.8778\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.3841 - acc: 0.8949 - val_loss: 0.5536 - val_acc: 0.8778\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.3575 - acc: 0.8962 - val_loss: 0.5018 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 00053: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f25c85fd0b8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(training_generator, \n",
    "                   validation_data=validation_generator,\n",
    "                   epochs=100, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Custom Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 512, 512, 1)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='53ac4693-bf7c-4ea7-b928-7e815794dfce'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 12\n",
    "params = {'batch_size': batch_size,\n",
    "          'n_classes': 99,\n",
    "          'shuffle': True}\n",
    "\n",
    "\n",
    "images_training_generator = DataGenerator(X_img_tr,y_tr, **params)\n",
    "images_validation_generator = DataGenerator(X_img_val,y_val, **params)\n",
    "im, y = images_training_generator.__getitem__(2)\n",
    "print(im.shape)\n",
    "plt.figure(figsize=(8,8))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3,3,i+1)\n",
    "    ax.axis('off')\n",
    "    plt.imshow(im[i,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image (InputLayer)           (None, 512, 512, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 509, 509, 12)      204       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 254, 254, 12)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 251, 251, 32)      6176      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 125, 125, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 122, 122, 32)      16416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 61, 61, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 58, 58, 16)        8208      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 29, 29, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 13456)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 13456)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               1345700   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 99)                9999      \n",
      "=================================================================\n",
      "Total params: 1,386,703\n",
      "Trainable params: 1,386,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image = Input(shape=(image_max_size, image_max_size, 1), name='image')\n",
    "# Pass it through the first convolutional layer\n",
    "x = Conv2D(12, (4, 4), activation = 'relu')(image)\n",
    "x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "\n",
    "# Now through the second convolutional layer\n",
    "x = (Conv2D(32, (4, 4),  activation = 'relu'))(x)\n",
    "x = (MaxPooling2D(pool_size=(2, 2)))(x)\n",
    "\n",
    "# Now through the second convolutional layer\n",
    "x = (Conv2D(32, (4, 4),  activation = 'relu'))(x)\n",
    "x = (MaxPooling2D(pool_size=(2, 2)))(x)\n",
    "\n",
    "x = (Conv2D(16, (4, 4),  activation = 'relu'))(x)\n",
    "x = (MaxPooling2D(pool_size=(2, 2)))(x)\n",
    "\n",
    "#x = (Conv2D(16, (5, 5),  activation = 'relu'))(x)\n",
    "#x = (MaxPooling2D(pool_size=(2, 2)))(x)\n",
    "\n",
    "# Flatten our array\n",
    "x = Flatten()(x)\n",
    "# Define the pre-extracted feature input\n",
    "x = Dropout(.5)(x)\n",
    "\n",
    "# Add a fully connected layer just like in a normal MLP\n",
    "x = Dense(100, activation='relu')(x)\n",
    "\n",
    "# Get the final output\n",
    "out = Dense(n_cats, activation='softmax')(x)\n",
    "# How we create models with the Functional API\n",
    "model = Model(inputs=image, outputs=out)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "66/66 [==============================] - 4s 62ms/step - loss: 4.1306 - acc: 0.0783 - val_loss: 2.9415 - val_acc: 0.2500\n",
      "Epoch 2/100\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 1.9321 - acc: 0.4823 - val_loss: 1.8866 - val_acc: 0.4896\n",
      "Epoch 3/100\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.9857 - acc: 0.6995 - val_loss: 1.7727 - val_acc: 0.5313\n",
      "Epoch 4/100\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.5965 - acc: 0.8194 - val_loss: 1.9253 - val_acc: 0.5729\n",
      "Epoch 5/100\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.4121 - acc: 0.8725 - val_loss: 2.0852 - val_acc: 0.5417\n",
      "Epoch 6/100\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.2403 - acc: 0.9343 - val_loss: 2.2344 - val_acc: 0.5833\n",
      "Epoch 7/100\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.1843 - acc: 0.9508 - val_loss: 2.5973 - val_acc: 0.5417\n",
      "Epoch 8/100\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.1257 - acc: 0.9646 - val_loss: 2.3776 - val_acc: 0.5521\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 9/100\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.0395 - acc: 0.9886 - val_loss: 2.1248 - val_acc: 0.6146\n",
      "Epoch 10/100\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.0289 - acc: 0.9912 - val_loss: 2.3649 - val_acc: 0.5937\n",
      "Epoch 11/100\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.0116 - acc: 0.9975 - val_loss: 2.3253 - val_acc: 0.6042\n",
      "Epoch 12/100\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.0183 - acc: 0.9937 - val_loss: 2.2358 - val_acc: 0.6250\n",
      "Epoch 13/100\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.0096 - acc: 0.9949 - val_loss: 2.6130 - val_acc: 0.5625\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 00013: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f25c80d7f60>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(images_training_generator, \n",
    "                    validation_data=images_validation_generator,\n",
    "                   epochs=100, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using images but also doing data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_augmentator= ImageDataGenerator(\n",
    "        #featurewise_center=True,\n",
    "        #featurewise_std_normalization=True,\n",
    "        rotation_range=30,\n",
    "        zoom_range=0.1,\n",
    "        width_shift_range=0.02,\n",
    "        height_shift_range=0.02,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims, ys = test_augmentator.flow(X_img_tr, y_tr, batch_size=9).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='1571b9d7-11df-4fcd-9292-98766d746f39'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3,3,i+1)\n",
    "    ax.axis('off')\n",
    "    plt.imshow(ims[i,:,:,0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Own data generator with augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "class ImageGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, features, targets, \n",
    "                 n_classes =99, \n",
    "                 batch_size=32,  \n",
    "                 shuffle=True, \n",
    "                 repeats = 1):\n",
    "        \n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        self.n_vals = len(targets)\n",
    "        # since we are using data agumentation we repeat the number of times we show each image.\n",
    "        # we show the same original image but it can be rotated or flipper each time, so it is not the \"same\" image\n",
    "        self.list_IDs = np.repeat(np.arange(self.n_vals),repeats) #OJO con esto, deberian ser las imagenes validas si queremos hacer bien las cosas\n",
    "        self.batch_size = batch_size\n",
    "        self.features = features\n",
    "        self.shuffle = shuffle\n",
    "        self.targets = targets\n",
    "        self.targets_mc = keras.utils.to_categorical(targets, num_classes=self.n_classes)\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        \n",
    "        self.agumentator = ImageDataGenerator(\n",
    "        #featurewise_center=True,\n",
    "        #featurewise_std_normalization=True,\n",
    "        rotation_range=30,\n",
    "        zoom_range=0.1,\n",
    "        width_shift_range=0.01,\n",
    "        height_shift_range=0.01,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True)\n",
    "          \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = self.features[list_IDs_temp]\n",
    "        y = self.targets_mc[list_IDs_temp]\n",
    "\n",
    "        X, y = self.agumentator.flow(X, y, batch_size=self.batch_size).next()\n",
    "        \n",
    "#        # Generate data\n",
    "#        for i, ID in enumerate(list_IDs_temp):\n",
    "#            # Store sample\n",
    "#            X[i,] = np.load('data/' + ID + '.npy')\n",
    "#\n",
    "#            # Store class\n",
    "#            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image (InputLayer)           (None, 512, 512, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 508, 508, 12)      312       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 254, 254, 12)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 250, 250, 32)      9632      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 125, 125, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 121, 121, 32)      25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 60, 60, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 56, 56, 16)        12816     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               1254500   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 99)                9999      \n",
      "=================================================================\n",
      "Total params: 1,312,891\n",
      "Trainable params: 1,312,891\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image = Input(shape=(image_max_size, image_max_size, 1), name='image')\n",
    "# Pass it through the first convolutional layer\n",
    "x = Conv2D(12, (5, 5), activation = 'relu')(image)\n",
    "x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "\n",
    "# Now through the second convolutional layer\n",
    "x = (Conv2D(32, (5, 5),  activation = 'relu'))(x)\n",
    "x = (MaxPooling2D(pool_size=(2, 2)))(x)\n",
    "\n",
    "# Now through the second convolutional layer\n",
    "x = (Conv2D(32, (5, 5),  activation = 'relu'))(x)\n",
    "x = (MaxPooling2D(pool_size=(2, 2)))(x)\n",
    "\n",
    "x = (Conv2D(16, (5, 5),  activation = 'relu'))(x)\n",
    "x = (MaxPooling2D(pool_size=(2, 2)))(x)\n",
    "\n",
    "\n",
    "# Flatten our array\n",
    "x = Flatten()(x)\n",
    "# Define the pre-extracted feature input\n",
    "x = Dropout(.5)(x)\n",
    "\n",
    "# Add a fully connected layer just like in a normal MLP\n",
    "x = Dense(100, activation='relu')(x)\n",
    "\n",
    "# Get the final output\n",
    "out = Dense(n_cats, activation='softmax')(x)\n",
    "# How we create models with the Functional API\n",
    "model = Model(inputs=image, outputs=out)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "params = {'batch_size': batch_size,\n",
    "          'n_classes': 99,\n",
    "          'shuffle': True,}\n",
    "images_validation_generator = DataGenerator(X_img_val,y_val, **params) # <-- no augmentation\n",
    "\n",
    "params['repeats'] = 3\n",
    "images_training_generator = ImageGenerator(X_img_tr,y_tr, **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "148/148 [==============================] - 22s 150ms/step - loss: 0.6782 - acc: 0.7618 - val_loss: 0.9660 - val_acc: 0.7604\n",
      "Epoch 2/100\n",
      "148/148 [==============================] - 22s 149ms/step - loss: 0.6623 - acc: 0.7741 - val_loss: 0.8169 - val_acc: 0.7708\n",
      "Epoch 3/100\n",
      "148/148 [==============================] - 21s 145ms/step - loss: 0.6041 - acc: 0.7867 - val_loss: 0.8042 - val_acc: 0.7708\n",
      "Epoch 4/100\n",
      "148/148 [==============================] - 21s 142ms/step - loss: 0.5565 - acc: 0.8024 - val_loss: 1.4293 - val_acc: 0.5625\n",
      "Epoch 5/100\n",
      "148/148 [==============================] - 22s 148ms/step - loss: 0.5409 - acc: 0.8117 - val_loss: 1.6936 - val_acc: 0.5729\n",
      "Epoch 6/100\n",
      "148/148 [==============================] - 21s 143ms/step - loss: 0.5653 - acc: 0.8036 - val_loss: 1.2173 - val_acc: 0.6875\n",
      "Epoch 7/100\n",
      "148/148 [==============================] - 22s 152ms/step - loss: 0.5534 - acc: 0.8091 - val_loss: 0.7461 - val_acc: 0.8229\n",
      "Epoch 8/100\n",
      "148/148 [==============================] - 22s 150ms/step - loss: 0.5161 - acc: 0.8066 - val_loss: 0.6497 - val_acc: 0.8542\n",
      "Epoch 9/100\n",
      "148/148 [==============================] - 20s 138ms/step - loss: 0.5101 - acc: 0.8146 - val_loss: 1.2037 - val_acc: 0.6875\n",
      "Epoch 10/100\n",
      "148/148 [==============================] - 22s 146ms/step - loss: 0.4962 - acc: 0.8180 - val_loss: 1.2081 - val_acc: 0.6771\n",
      "Epoch 11/100\n",
      "148/148 [==============================] - 20s 138ms/step - loss: 0.4862 - acc: 0.8298 - val_loss: 0.8292 - val_acc: 0.7604\n",
      "Epoch 12/100\n",
      "148/148 [==============================] - 21s 144ms/step - loss: 0.4720 - acc: 0.8319 - val_loss: 0.7904 - val_acc: 0.7812\n",
      "Epoch 13/100\n",
      "148/148 [==============================] - 21s 143ms/step - loss: 0.4593 - acc: 0.8391 - val_loss: 2.1456 - val_acc: 0.5729\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 14/100\n",
      "148/148 [==============================] - 20s 135ms/step - loss: 0.3765 - acc: 0.8674 - val_loss: 0.8458 - val_acc: 0.7604\n",
      "Epoch 15/100\n",
      "148/148 [==============================] - 23s 155ms/step - loss: 0.3494 - acc: 0.8780 - val_loss: 1.2974 - val_acc: 0.6667\n",
      "Epoch 16/100\n",
      "148/148 [==============================] - 21s 143ms/step - loss: 0.3222 - acc: 0.8801 - val_loss: 1.1521 - val_acc: 0.7292\n",
      "Epoch 17/100\n",
      "Epoch 16/100\n",
      "148/148 [==============================] - 21s 141ms/step - loss: 0.3017 - acc: 0.8986 - val_loss: 1.7488 - val_acc: 0.6146\n",
      "Epoch 18/100\n",
      "148/148 [==============================] - 21s 139ms/step - loss: 0.3213 - acc: 0.8822 - val_loss: 1.0365 - val_acc: 0.7292\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 00018: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f254c199e80>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(images_training_generator, \n",
    "                    validation_data=images_validation_generator,\n",
    "                   epochs=100, callbacks = callbacks,\n",
    "                   use_multiprocessing=True,\n",
    "                    max_queue_size=10,\n",
    "                    workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features and Image generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are going to build a generator that returns both, images and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, x_tuple, targets, \n",
    "                 n_classes =99, \n",
    "                 batch_size=32,  \n",
    "                 shuffle=True,\n",
    "                 repeats = 1,\n",
    "                 validate = False):\n",
    "\n",
    "        # in validation mode we want the data as it comes, no agumentation or changes\n",
    "        self.validate = validate\n",
    "        if self.validate:\n",
    "            repeats = 1\n",
    "            \n",
    "        features, images = x_tuple[0], x_tuple[1]\n",
    "        self.n_classes = n_classes\n",
    "        self.n_vals = len(targets)\n",
    "        # since we are using data agumentation we repeat the number of times we show each image.\n",
    "        # we show the same original image but it can be rotated or flipper each time, so it is not the \"same\" image\n",
    "        self.list_IDs = np.repeat(np.arange(self.n_vals),repeats) #OJO con esto, deberian ser las imagenes validas si queremos hacer bien las cosas\n",
    "        self.batch_size = batch_size\n",
    "        self.features = features\n",
    "        self.images = images        \n",
    "        print('feature: {}'.format(self.features.shape))\n",
    "        print('images: {}'.format(self.images.shape))\n",
    "        self.shuffle = shuffle\n",
    "        self.targets = targets\n",
    "        self.targets_mc = keras.utils.to_categorical(targets, num_classes=self.n_classes)\n",
    "        self.indexes = np.arange(len(self.list_IDs)) #this is ok\n",
    "        \n",
    "        self.agumentator = ImageDataGenerator(\n",
    "                                    #featurewise_center=True,\n",
    "                                    #featurewise_std_normalization=True,\n",
    "                                    rotation_range=30,\n",
    "                                    zoom_range=0.1,\n",
    "                                    width_shift_range=0.01,\n",
    "                                    height_shift_range=0.01,\n",
    "                                    horizontal_flip=True,\n",
    "                                    vertical_flip=True)\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        Xi, yi = self.__image_generation(list_IDs_temp)        \n",
    "        Xf, yf = self.__feature_generation(list_IDs_temp)\n",
    "        if np.all(yf==yi):\n",
    "            y = yf\n",
    "        else:\n",
    "            print(np.argmax(self.targets_mc[list_IDs_temp],axis=1))\n",
    "            print(np.argmax(yf, axis=1))\n",
    "            print(np.argmax(yi, axis=1))\n",
    "            raise ValueError('not equal')\n",
    "                \n",
    "            \n",
    "        return ([Xf,Xi], y)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = self.list_IDs\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __feature_generation(self, list_IDs_temp):\n",
    "        y = self.targets_mc[list_IDs_temp]\n",
    "        X = self.features[list_IDs_temp]\n",
    "        return X, y\n",
    "        \n",
    "    def __image_generation(self, list_IDs_temp):\n",
    "        # Initialization\n",
    "        X = self.images[list_IDs_temp]\n",
    "        yr = self.targets_mc[list_IDs_temp]\n",
    "        if not self.validate:\n",
    "#            X, y = self.agumentator.flow(X, y, batch_size=self.batch_size).next()\n",
    "            X, y = self.agumentator.flow(X, yr, batch_size=len(list_IDs_temp), shuffle=False).next()            \n",
    "            if not np.all(y==yr):\n",
    "                print('not equal after agumentator')\n",
    "        else:\n",
    "            y = yr\n",
    "        \n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: (792, 192)\n",
      "images: (792, 512, 512, 1)\n",
      "feature: (99, 192)\n",
      "images: (99, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "params = {'batch_size': batch_size,\n",
    "          'n_classes': 99,\n",
    "          'shuffle': True,\n",
    "         }\n",
    "params['repeats'] = 3\n",
    "ensemble_training_generator = EnsembleGenerator((X_num_tr,X_img_tr),y_tr, **params)\n",
    "params['validate']=True\n",
    "ensemble_validate_generator = EnsembleGenerator((X_num_val,X_img_val),y_val, **params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(792, 192)\n",
      "(792, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "print(ensemble_training_generator.features.shape)\n",
    "print(ensemble_training_generator.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image_input (InputLayer)        (None, 512, 512, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 507, 507, 12) 444         image_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 253, 253, 12) 0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 250, 250, 32) 6176        max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 125, 125, 32) 0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 122, 122, 32) 16416       max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 61, 61, 32)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 58, 58, 16)   8208        max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D) (None, 29, 29, 16)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 26, 26, 16)   4112        max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "feature_input (InputLayer)      (None, 192)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D) (None, 13, 13, 16)   0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 100)          19300       feature_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 2704)         0           max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 100)          0           dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 2704)         0           flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 100)          10100       dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 100)          270500      dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 200)          0           dense_27[0][0]                   \n",
      "                                                                 dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 200)          0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Dense_conc (Dense)              (None, 100)          20100       dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 50)           5050        Dense_conc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 99)           5049        dense_29[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 365,455\n",
      "Trainable params: 365,455\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model = Sequential()\n",
    "#model.add(Dense(64, input_shape = (192,), activation = 'relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "#model.add(Dense(128,activation = 'relu'))\n",
    "#model.add(Dense(n_cats,activation = 'softmax', name = 'out_layer'))\n",
    "\n",
    "feature = Input(shape=(192,), name = 'feature_input')\n",
    "xf = Dense(100, activation = 'relu')(feature)\n",
    "xf = Dropout(0.3)(xf)\n",
    "xf = Dense(100, activation='relu')(xf)\n",
    "\n",
    "image = Input(shape=(image_max_size, image_max_size, 1), name='image_input')\n",
    "# Pass it through the first convolutional layer\n",
    "xi = Conv2D(12, (6, 6), activation = 'relu')(image)\n",
    "xi = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(xi)\n",
    "xi = (Conv2D(32, (4, 4),  activation = 'relu'))(xi)\n",
    "xi = (MaxPooling2D(pool_size=(2, 2)))(xi)\n",
    "xi = (Conv2D(32, (4, 4),  activation = 'relu'))(xi)\n",
    "xi = (MaxPooling2D(pool_size=(2, 2)))(xi)\n",
    "xi = (Conv2D(16, (4, 4),  activation = 'relu'))(xi)\n",
    "xi = (MaxPooling2D(pool_size=(2, 2)))(xi)\n",
    "if image_max_size>256:\n",
    "    xi = (Conv2D(16, (4, 4),  activation = 'relu'))(xi)\n",
    "    xi = (MaxPooling2D(pool_size=(2, 2)))(xi)\n",
    "xi = Flatten()(xi) # Flatten our array\n",
    "xi = Dropout(.5)(xi)\n",
    "xi = Dense(100, activation='relu')(xi)\n",
    "\n",
    "xe = Concatenate(axis = -1)([xf, xi])\n",
    "xe = Dropout(0.1)(xe)\n",
    "xe = Dense(100, activation='relu', name='Dense_conc')(xe)\n",
    "xe = Dense(50, activation='relu')(xe)\n",
    "\n",
    "# Get the final output\n",
    "out = Dense(n_cats, activation='softmax')(xe)\n",
    "# How we create models with the Functional API\n",
    "model = Model(inputs=[feature,image], outputs=out)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "147/148 [============================>.] - ETA: 0s - loss: 1.9192 - acc: 0.4018Epoch 1/100\n",
      "148/148 [==============================] - 21s 144ms/step - loss: 1.9142 - acc: 0.4033 - val_loss: 1.6638 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "Epoch 1/100\n",
      "148/148 [==============================] - 21s 143ms/step - loss: 1.3621 - acc: 0.5490 - val_loss: 1.2068 - val_acc: 0.6771\n",
      "Epoch 3/100\n",
      "148/148 [==============================] - 20s 136ms/step - loss: 1.0139 - acc: 0.6605 - val_loss: 1.0895 - val_acc: 0.7083\n",
      "Epoch 4/100\n",
      "148/148 [==============================] - 22s 145ms/step - loss: 0.8536 - acc: 0.7061 - val_loss: 0.8811 - val_acc: 0.7812\n",
      "Epoch 5/100\n",
      "148/148 [==============================] - 21s 144ms/step - loss: 0.7753 - acc: 0.7335 - val_loss: 0.5851 - val_acc: 0.7812\n",
      "Epoch 6/100\n",
      "148/148 [==============================] - 22s 148ms/step - loss: 0.6444 - acc: 0.7804 - val_loss: 0.7685 - val_acc: 0.7708\n",
      "Epoch 7/100\n",
      "148/148 [==============================] - 21s 141ms/step - loss: 0.5464 - acc: 0.8053 - val_loss: 0.6926 - val_acc: 0.8542\n",
      "Epoch 8/100\n",
      "148/148 [==============================] - 21s 139ms/step - loss: 0.4354 - acc: 0.8552 - val_loss: 0.6847 - val_acc: 0.8125\n",
      "Epoch 9/100\n",
      "148/148 [==============================] - 21s 139ms/step - loss: 0.4110 - acc: 0.8602 - val_loss: 0.6602 - val_acc: 0.8021\n",
      "Epoch 10/100\n",
      "\n",
      "148/148 [==============================] - 21s 143ms/step - loss: 0.3444 - acc: 0.8796 - val_loss: 0.6042 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 11/100\n",
      "148/148 [==============================] - 19s 130ms/step - loss: 0.2785 - acc: 0.8982 - val_loss: 0.5505 - val_acc: 0.8438\n",
      "Epoch 12/100\n",
      "148/148 [==============================] - 20s 138ms/step - loss: 0.2492 - acc: 0.9139 - val_loss: 0.4949 - val_acc: 0.8542\n",
      "Epoch 13/100\n",
      "148/148 [==============================] - 22s 145ms/step - loss: 0.2120 - acc: 0.9341 - val_loss: 0.4424 - val_acc: 0.8854\n",
      "Epoch 14/100\n",
      "148/148 [==============================] - 21s 141ms/step - loss: 0.2079 - acc: 0.9244 - val_loss: 0.4291 - val_acc: 0.8438\n",
      "Epoch 15/100\n",
      "148/148 [==============================] - 21s 143ms/step - loss: 0.1870 - acc: 0.9345 - val_loss: 0.4846 - val_acc: 0.8854\n",
      "Epoch 16/100\n",
      "148/148 [==============================] - 22s 145ms/step - loss: 0.2008 - acc: 0.9345 - val_loss: 0.4786 - val_acc: 0.8854\n",
      "Epoch 17/100\n",
      "148/148 [==============================] - 22s 146ms/step - loss: 0.2124 - acc: 0.9299 - val_loss: 0.4234 - val_acc: 0.8750\n",
      "Epoch 18/100\n",
      "148/148 [==============================] - 21s 143ms/step - loss: 0.1676 - acc: 0.9434 - val_loss: 0.3657 - val_acc: 0.9167\n",
      "Epoch 19/100\n",
      "148/148 [==============================] - 21s 144ms/step - loss: 0.1770 - acc: 0.9400 - val_loss: 0.4758 - val_acc: 0.8854\n",
      "Epoch 20/100\n",
      "148/148 [==============================] - 20s 138ms/step - loss: 0.1466 - acc: 0.9519 - val_loss: 0.4738 - val_acc: 0.8646\n",
      "Epoch 21/100\n",
      "148/148 [==============================] - 21s 144ms/step - loss: 0.1646 - acc: 0.9430 - val_loss: 0.4169 - val_acc: 0.8854\n",
      "Epoch 22/100\n",
      "147/148 [============================>.] - ETA: 0s - loss: 0.1765 - acc: 0.9439Epoch 22/100\n",
      "148/148 [==============================] - 22s 146ms/step - loss: 0.1757 - acc: 0.9443 - val_loss: 0.3838 - val_acc: 0.9167\n",
      "Epoch 23/100\n",
      "148/148 [==============================] - 21s 140ms/step - loss: 0.1451 - acc: 0.9481 - val_loss: 0.4036 - val_acc: 0.9062\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 24/100\n",
      "148/148 [==============================] - 22s 151ms/step - loss: 0.1214 - acc: 0.9599 - val_loss: 0.3596 - val_acc: 0.9167\n",
      "Epoch 25/100\n",
      "148/148 [==============================] - 20s 138ms/step - loss: 0.1228 - acc: 0.9599 - val_loss: 0.3685 - val_acc: 0.9167\n",
      "Epoch 26/100\n",
      "148/148 [==============================] - 20s 138ms/step - loss: 0.1023 - acc: 0.9683 - val_loss: 0.3711 - val_acc: 0.9062\n",
      "Epoch 27/100\n",
      "148/148 [==============================] - 21s 145ms/step - loss: 0.1105 - acc: 0.9603 - val_loss: 0.4139 - val_acc: 0.8958\n",
      "Epoch 28/100\n",
      "148/148 [==============================] - 21s 143ms/step - loss: 0.1057 - acc: 0.9628 - val_loss: 0.3636 - val_acc: 0.9271\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 00028: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f250078abe0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(ensemble_training_generator, \n",
    "                    validation_data=ensemble_validate_generator,\n",
    "                    epochs=100, \n",
    "                    callbacks = callbacks,\n",
    "                    use_multiprocessing=True,\n",
    "                    max_queue_size=10,\n",
    "                    workers=4)\n",
    "            \n",
    "        # 'max_queue_size':5, \n",
    "         # 'workers':2, \n",
    "         # 'use_multiprocessing':True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.041666666666666664,\n",
       " 0.3333333333333333,\n",
       " 0.5520833333333334,\n",
       " 0.6875,\n",
       " 0.7291666666666666,\n",
       " 0.8020833333333334,\n",
       " 0.7916666666666666,\n",
       " 0.8020833333333334,\n",
       " 0.8229166666666666,\n",
       " 0.8645833333333334,\n",
       " 0.8541666666666666,\n",
       " 0.8854166666666666,\n",
       " 0.84375,\n",
       " 0.8854166666666666,\n",
       " 0.8645833333333334,\n",
       " 0.8854166666666666,\n",
       " 0.8958333333333334,\n",
       " 0.8645833333333334,\n",
       " 0.875,\n",
       " 0.8645833333333334,\n",
       " 0.8958333333333334,\n",
       " 0.90625,\n",
       " 0.90625,\n",
       " 0.8229166666666666,\n",
       " 0.9166666666666666,\n",
       " 0.9166666666666666,\n",
       " 0.9270833333333334,\n",
       " 0.9375,\n",
       " 0.8958333333333334,\n",
       " 0.9270833333333334,\n",
       " 0.8854166666666666,\n",
       " 0.8958333333333334,\n",
       " 0.90625,\n",
       " 0.9166666666666666,\n",
       " 0.9166666666666666,\n",
       " 0.9479166666666666,\n",
       " 0.9166666666666666,\n",
       " 0.9166666666666666]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception('hasta aca warxhs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, NumpyArrayIterator, array_to_img\n",
    "\n",
    "# A little hacky piece of code to get access to the indices of the images\n",
    "# the data augmenter is working with.\n",
    "class ImageDataGenerator2(ImageDataGenerator):\n",
    "    def flow(self, X, y=None, batch_size=26, shuffle=True, seed=None,\n",
    "             save_to_dir=None, save_prefix='', save_format='jpeg'):\n",
    "        return NumpyArrayIterator2(\n",
    "            X, y, self,\n",
    "            batch_size=batch_size, shuffle=shuffle, seed=seed,\n",
    "            data_format=self.data_format,\n",
    "            save_to_dir=save_to_dir, save_prefix=save_prefix, save_format=save_format)\n",
    "\n",
    "\n",
    "class NumpyArrayIterator2(NumpyArrayIterator):\n",
    "    def next(self):\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch\n",
    "        # see http://anandology.com/blog/using-iterators-and-generators/\n",
    "        with self.lock:\n",
    "            # We changed index_array to self.index_array\n",
    "            self.index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "        # The transformation of images is not under thread lock so it can be done in parallel\n",
    "        batch_x = np.zeros(tuple([current_batch_size] + list(self.X.shape)[1:]))\n",
    "        for i, j in enumerate(self.index_array):\n",
    "            x = self.X[j]\n",
    "            x = self.image_data_generator.random_transform(x.astype('float32'))\n",
    "            x = self.image_data_generator.standardize(x)\n",
    "            batch_x[i] = x\n",
    "        if self.save_to_dir:\n",
    "            for i in range(current_batch_size):\n",
    "                img = array_to_img(batch_x[i], self.data_format, scale=True)\n",
    "                fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,\n",
    "                                                                  index=current_index + i,\n",
    "                                                                  hash=np.random.randint(1e4),\n",
    "                                                                  format=self.save_format)\n",
    "                img.save(os.path.join(self.save_to_dir, fname))\n",
    "        if self.y is None:\n",
    "            return batch_x\n",
    "        batch_y = self.y[self.index_array]\n",
    "        return batch_x, batch_y\n",
    "\n",
    "print('Creating Data Augmenter...')\n",
    "imgen = ImageDataGenerator2(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest')\n",
    "imgen_train = imgen.flow(X_img_tr, y_tr_cat, seed=np.random.randint(1, 10000))\n",
    "print('Finished making data augmenter...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgen_train[-2][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Convolution2D, MaxPooling2D, Flatten, Input, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(imgen_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def combined_model():\n",
    "\n",
    "    # Define the image input\n",
    "    image = Input(shape=(96, 96, 1), name='image')\n",
    "    # Pass it through the first convolutional layer\n",
    "    x = Convolution2D(8, 5, 5, input_shape=(96, 96, 1), border_mode='same')(image)\n",
    "    x = (Activation('relu'))(x)\n",
    "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "\n",
    "    # Now through the second convolutional layer\n",
    "    x = (Convolution2D(32, 5, 5, border_mode='same'))(x)\n",
    "    x = (Activation('relu'))(x)\n",
    "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "\n",
    "    # Flatten our array\n",
    "    x = Flatten()(x)\n",
    "    # Define the pre-extracted feature input\n",
    "    numerical = Input(shape=(192,), name='numerical')\n",
    "    # Concatenate the output of our convnet with our pre-extracted feature input\n",
    "    concatenated = Concatenate()([x, numerical])\n",
    "\n",
    "    # Add a fully connected layer just like in a normal MLP\n",
    "    x = Dense(100, activation='relu')(concatenated)\n",
    "    x = Dropout(.5)(x)\n",
    "\n",
    "    # Get the final output\n",
    "    out = Dense(99, activation='softmax')(x)\n",
    "    # How we create models with the Functional API\n",
    "    model = Model(input=[image, numerical], output=out)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "print('Creating the model...')\n",
    "model = combined_model()\n",
    "print('Model created!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "def combined_generator(imgen, X):\n",
    "    \"\"\"\n",
    "    A generator to train our keras neural network. It\n",
    "    takes the image augmenter generator and the array\n",
    "    of the pre-extracted features.\n",
    "    It yields a minibatch and will run indefinitely\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        for i in range(X.shape[0]):\n",
    "            # Get the image batch and labels\n",
    "            batch_img, batch_y = next(imgen)\n",
    "            # This is where that change to the source code we\n",
    "            # made will come in handy. We can now access the indicies\n",
    "            # of the images that imgen gave us.\n",
    "            x = X[imgen.index_array]\n",
    "            yield [batch_img, x], batch_y\n",
    "\n",
    "# autosave best Model\n",
    "best_model_file = \"leafnet.h5\"\n",
    "best_model = ModelCheckpoint(best_model_file, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "print('Training model...')\n",
    "history = model.fit_generator(combined_generator(imgen_train, X_num_tr),\n",
    "                              samples_per_epoch=X_num_tr.shape[0],\n",
    "                              nb_epoch=89,\n",
    "                              validation_data=([X_img_val, X_num_val], y_val_cat),\n",
    "                              nb_val_samples=X_num_val.shape[0],\n",
    "                              verbose=0,\n",
    "                              callbacks=[best_model])\n",
    "\n",
    "print('Loading the best model...')\n",
    "model = load_model(best_model_file)\n",
    "print('Best Model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "def combined_generator(imgen, X):\n",
    "    \"\"\"\n",
    "    A generator to train our keras neural network. It\n",
    "    takes the image augmenter generator and the array\n",
    "    of the pre-extracted features.\n",
    "    It yields a minibatch and will run indefinitely\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        for i in range(X.shape[0]):\n",
    "            # Get the image batch and labels\n",
    "            batch_img, batch_y = next(imgen)\n",
    "            # This is where that change to the source code we\n",
    "            # made will come in handy. We can now access the indicies\n",
    "            # of the images that imgen gave us.\n",
    "            x = X[imgen.index_array]\n",
    "            yield [batch_img, x], batch_y\n",
    "\n",
    "# autosave best Model\n",
    "best_model_file = \"leafnet.h5\"\n",
    "best_model = ModelCheckpoint(best_model_file, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "print('Training model...')\n",
    "history = model.fit_generator(combined_generator(imgen_train, X_num_tr),\n",
    "                              samples_per_epoch=X_num_tr.shape[0],\n",
    "                              nb_epoch=89,\n",
    "                              validation_data=([X_img_val, X_num_val], y_val_cat),\n",
    "                              nb_val_samples=X_num_val.shape[0],\n",
    "                              verbose=0,\n",
    "                              callbacks=[best_model])\n",
    "\n",
    "print('Loading the best model...')\n",
    "model = load_model(best_model_file)\n",
    "print('Best Model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vec['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(img, max_dim=96):\n",
    "    \"\"\"\n",
    "    Resize the image to so the maximum side is of size max_dim\n",
    "    Returns a new image of the right size\n",
    "    \"\"\"\n",
    "    # Get the axis with the larger dimension\n",
    "    max_ax = max((0, 1), key=lambda i: img.size[i])\n",
    "    # Scale both axes so the image's largest dimension is max_dim\n",
    "    scale = max_dim / float(img.size[max_ax])\n",
    "    return img.resize((int(img.size[0] * scale), int(img.size[1] * scale)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for id_num in id_vec['id'].values:\n",
    "    im = load_img(images_folder + str(id_num) +'.jpg')\n",
    "    images.append(np.expand_dims(im,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_to_array(im).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_img(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_d0 = 0\n",
    "max_d1 = 0\n",
    "for im in images:\n",
    "    max_d0 = max(max_d0,im.shape[0])\n",
    "    max_d1 = max(max_d1,im.shape[1])   \n",
    "print(max_d0, max_d1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_exp = []\n",
    "for im in images:\n",
    "#    print(im.shape)\n",
    "    s0,s1,s3 = im.shape\n",
    "    extra_0 =   max_d0 -s0\n",
    "    extra_1 =   max_d1 - s1\n",
    "    expanded = np.zeros((max_d0, max_d1, 1))\n",
    "    b0, b1 = int(np.floor(extra_0/2)), int(np.floor(extra_1/2))\n",
    " #   print(b0,b1)\n",
    "    expanded[b0:b0+s0,b1:b1+s1,:] = im\n",
    "    images_exp.append(expanded)\n",
    "\n",
    "images_exp = np.array(images_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idd = 250\n",
    "print(images_exp[idd].shape)\n",
    "plt.figure()\n",
    "plt.imshow(images_exp[idd][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (4, 4), input_shape=(1089, 1633,1),\n",
    "               activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=99, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(in_layer, output_layer)\n",
    "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in_layer = Input(shape=(1089, 1633,1))\n",
    "#x = Conv2D(16,(4,4), activation = 'elu')(in_layer)  # single stride 4x4 filter for 16 maps\n",
    "#x = Conv2D(32,(4,4), activation = 'elu')(x)         # single stride 4x4 filter for 32 maps\n",
    "#x = Dropout(0.5)(x)\n",
    "#x = Conv2D(64,(4,4), activation = 'elu')(x)         # single stride 4x4 filter for 64 maps\n",
    "#x = Dropout(0.5)(x)\n",
    "#x = Conv2D(128, (1,1))(x)                           # finally 128 maps for global average-pool\n",
    "#x = GlobalMaxPooling2D()(x)                     # pseudo-dense 128 layer\n",
    "#output_layer = Dense(99, activation = \"softmax\")(x) # softmax output\n",
    "#\n",
    "#model = Model(in_layer, output_layer)\n",
    "#model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\",\n",
    "#            metrics=[\"accuracy\"])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(images_exp, target_mc, batch_size = 1, epochs = 50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
